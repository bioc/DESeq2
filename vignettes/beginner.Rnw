%\VignetteIndexEntry{Beginner's guide to the "DESeq2" package}
%\VignettePackage{DESeq2}
%\VignetteEngine{knitr::knitr}

% To compile this document
% library('knitr'); rm(list=ls()); knit('beginner.Rnw')

\documentclass[12pt]{article}

\newcommand{\deseqtwo}{\textit{DESeq2}}
\newcommand{\lowtilde}{\raise.17ex\hbox{$\scriptstyle\mathtt{\sim}$}}

<<knitr, echo=FALSE, results="hide">>=
library("knitr")
opts_chunk$set(tidy=FALSE,dev="png",fig.show="hide",
               fig.width=4,fig.height=4.5,
               message=FALSE)
@ 

<<style, eval=TRUE, echo=FALSE, results="asis">>=
BiocStyle::latex()
@

<<loadDESeq2, echo=FALSE>>=
# in order to print version number below
library("DESeq2")
@


\author{Michael Love$^{1*}$, Simon Anders$^{2}$, Wolfgang Huber$^{2}$ \\[1em] \small{$^{1}$ Department of Biostatistics, Dana Farber Cancer Institute and} \\ \small{Harvard School of Public Health, Boston, US;} \\ \small{$^{2}$ European Molecular Biology Laboratory (EMBL), Heidelberg, Germany} \\ \small{\texttt{$^*$michaelisaiahlove (at) gmail.com}}}

\title{Beginner's guide to using the DESeq2 package}

\begin{document}

\maketitle

\begin{abstract}
  This vignette describes the statistical analysis of count matrices for systematic changes between
  conditions using the \deseqtwo{} package, and includes recommendations for producing count
  matrices from raw sequencing data.  This vignette is designed for users who are perhaps new to
  analyzing RNA-Seq or high-throughput sequencing data in R, and so goes at a slower pace,
  explaining each step in detail.  Another vignette, ``Differential analysis of count data -- the
  DESeq2 package'' covers more of the advanced details at a faster pace.

  \vspace{1em}
  
  \textbf{DESeq2 version:} \Sexpr{packageDescription("DESeq2")$Version}

  \vspace{1em}
  
  \begin{center}
    \begin{tabular}{ | l | }
      \hline 
      If you use \deseqtwo{} in published research, please cite:  \\
      \\
      M. I. Love, W. Huber, S. Anders: Moderated estimation of \\
      fold change and dispersion for RNA-Seq data with DESeq2. \\
      bioRxiv (2014). doi:10.1101/002832 \cite{Love:2014:biorxiv} \\
      \hline 
    \end{tabular}
  \end{center}

\end{abstract}

<<options, results="hide", echo=FALSE>>=
options(digits=3, width=80, prompt=" ", continue=" ")
@

\newpage

\tableofcontents

\section{Introduction}
In this vignette, you will learn how to produce a read count table -- such as arising from a
summarized RNA-Seq experiment -- analyze count tables for differentially expressed genes,  
visualize the results, add extra gene annotations, and cluster samples and genes
using transformed counts.

\section{Input data}

\subsection{Preparing count matrices}

As input, the \deseqtwo{} package expects count data as obtained, e.\,g.,
from RNA-Seq or another high-throughput sequencing experiment, in the form of a
matrix of integer values. The value in the $i$-th row and the $j$-th column of
the matrix tells how many reads have been mapped to gene $i$ in sample $j$.
Analogously, for other types of assays, the rows of the matrix might correspond
e.\,g.\ to binding regions (with ChIP-Seq) or peptide sequences (with
quantitative mass spectrometry).

The count values must be raw counts of sequencing reads. This is important
for \deseqtwo{}'s statistical model to hold, as only the actual
counts allow assessing the measurement precision correctly. Hence, please
do not supply other quantities, such as (rounded) normalized counts, or
counts of covered base pairs -- this will only lead to nonsensical results.

\subsection{Aligning reads to a reference}

The computational analysis of an RNA-Seq experiment begins earlier however, 
with a set of FASTQ files, which contain the bases for each read and their quality scores. 
These reads must first be aligned to a reference genome or transcriptome.
It is important to know if the sequencing experiment was single-end or
paired-end, as the alignment software will require the user specify
both FASTQ files for a paired-end experiment.

A number of software programs exist to align reads to the reference genome, 
and the development is too rapid for this document to provide a current 
list. We recommend reading benchmarking papers which discuss the advantages
and disadvantages of each software, which include accuracy, ability to 
align reads over splice junctions, speed, memory footprint, and many other 
features. 

We have experience using the TopHat2 spliced alignment 
software\footnote{\url{http://tophat.cbcb.umd.edu/}} \cite{Kim2013TopHat2}
in combination with the Bowtie index available at the Illumina iGenomes 
page\footnote{\url{http://tophat.cbcb.umd.edu/igenomes.html}}.  
For full details on this software and on the iGenomes, users should follow the links
to the manual and information provided in the links in the footnotes.
For example, the paired-end RNA-Seq reads for the \Biocexptpkg{parathyroidSE} package were aligned 
using TopHat2 with 8 threads, with the call:

\begin{verbatim}
  tophat2 -o file_tophat_out -p 8 genome file_1.fastq file_2.fastq 
  samtools sort -n file_tophat_out/accepted_hits.bam _sorted
\end{verbatim}

The second line sorts the reads by name rather than by genomic position, which is necessary
for counting paired-end reads within Bioconductor.
This command uses the SAMtools software\footnote{\url{http://samtools.sourceforge.net}} \cite{Li2009SAMtools}.
The BAM files for a number of sequencing runs can then be used to generate
coun matrices, as described in the following section.

\subsection{Counting reads in genes}

Once the reads have been aligned, there are a number of tools which can be
used to count the number of reads which can be unambiguously assigned to genomic features 
for each sample. These often take as input BAM or SAM alignment files and a file
specifiying the genomic features, e.g. GFF3 or GTF files specifying a gene model.

The following tools can be used generate count tables:

\begin{table}[h]
  \centering
  \footnotesize
\begin{tabular}{llll}
  function & package & output & \deseqtwo{} input function \\
  \hline
  \Rfunction{summarizeOverlaps} & \Biocpkg{GenomicAlignments} (Bioc) & \Rclass{SummarizedExperiment} & \Rfunction{DESeqDataSet} \\
  \texttt{htseq-count}\cite{Anders:2014:htseq} & \href{http://www-huber.embl.de/users/anders/HTSeq}{HTSeq} (Python) & count files & \Rfunction{DESeqDataSetFromHTSeq} \\
  \Rfunction{featureCounts}\cite{Liao2013feature} & \Biocpkg{Rsubread} (Bioc) & count matrix & \Rfunction{DESeqDataSetFromMatrix} \\
  \Rfunction{simpleRNASeq}\cite{Delhomme2012easy} & \Biocpkg{easyRNASeq} (Bioc) & \Rclass{SummarizedExperiment} & \Rfunction{DESeqDataSet} 
\end{tabular}
\end{table}

In order to produce correct counts, it is important to know if the experiment
was strand-specific or not. For example, \Rfunction{summarizeOverlaps} has the 
argument \Robject{ignore.strand}, which should be set to \Robject{TRUE} if
the experiment was not strand-specific and \Robject{FALSE} if the experiment
was strand-specific. Similarly, \texttt{htseq-count} has the argument \texttt{--stranded yes/no/reverse},
where strand-specific experiments should use \texttt{--stranded yes} and 
where \texttt{reverse} indicates that the positive strand reads should be counted 
to negative strand features.

The following example uses \Rfunction{summarizeOverlaps} for read counting,
while produces a \Rclass{SummarizedExperiment} object. This class of object 
contains a variety of information about an experiment, 
and will be described in more detail below.
We will demonstrate using example BAM files from the \Biocexptpkg{parathyroidSE} data package.
First, we read in the gene model from a GTF file, using \Rfunction{makeTranscriptDbFromGFF}.
Alternatively the \Rfunction{makeTranscriptDbFromBiomart} function can be used to 
automatically pull a gene model from Biomart. However, keeping the 
GTF file on hand has the advantage of bioinformatic reproducibility: the same gene model
can be made again, while past versions of gene models might not always be available on Biomart.
These GTF files can be downloaded from Ensembl's FTP site or other gene model
repositories. The third line here produces a \Rclass{GRangesList}
of all the exons grouped by gene.

<<eval=FALSE>>=
library( "GenomicFeatures" )
hse <- makeTranscriptDbFromGFF( "/path/to/your/genemodel.GTF", format="gtf" )
exonsByGene <- exonsBy( hse, by="gene" )
@ 

<<loadExonsByGene, echo=FALSE>>=
library("parathyroidSE")
library("GenomicFeatures")
data(exonsByGene)
@  

We specify the BAM files which will be used for counting.

<<eval=FALSE>>=
fls <- list.files( "/path/to/bam/files", pattern="bam$", full=TRUE )
@ 

<<locateFiles, echo=FALSE>>=
bamDir <- system.file("extdata",package="parathyroidSE",mustWork=TRUE)
fls <- list.files(bamDir, pattern="bam$",full=TRUE)
@ 

We indicate in Bioconductor that these fls are BAM files using the \Rfunction{BamFileList}
function. Here we also specify details about how the BAM files should be treated, e.g., 
only process $100000$ reads at a time. 

<<bamfilepaired>>=
library( "Rsamtools" )
bamLst <- BamFileList( fls, yieldSize=100000 )
@ 

We call \Rfunction{summarizeOverlaps} to count the reads.
We use the counting mode \Robject{"Union"} which indicates that reads which overlap any portion of
exactly one feature are counted. For more ihnformation on the various counting modes,
see the help page for \Rfunction{summarizeOverlaps}.
As this experiment was a paired-end, we specify \Robject{singleEnd=FALSE}.
As it was not a strand-specific protocol, we specify \Robject{ignore.strand=TRUE}.
\Robject{fragments=TRUE} indicates that we also want to count reads with unmapped pairs. 
This last argument is only for use with paired-end experiments.

<<sumOver>>=
library( "GenomicAlignments" )
se <- summarizeOverlaps( exonsByGene, bamLst,
                        mode="Union",
                        singleEnd=FALSE,
                        ignore.strand=TRUE,
                        fragments=TRUE )
@ 

<<beginner_plotSE, dev="pdf", echo=FALSE>>=
par(mar=c(0,0,0,0))
plot(1,1,xlim=c(0,100),ylim=c(0,100),bty="n",
     type="n",xlab="",ylab="",xaxt="n",yaxt="n")
polygon(c(45,80,80,45),c(10,10,70,70),col=rgb(1,0,0,.5),border=NA)
polygon(c(45,80,80,45),c(68,68,70,70),col=rgb(1,0,0,.5),border=NA)
text(62.5,40,"assay(s)")
text(62.5,30,"e.g. 'counts'")
polygon(c(20,40,40,20),c(10,10,70,70),col=rgb(0,0,1,.5),border=NA)
polygon(c(20,40,40,20),c(68,68,70,70),col=rgb(0,0,1,.5),border=NA)
text(30,40,"rowData")
polygon(c(45,80,80,45),c(75,75,90,90),col=rgb(.5,0,.5,.5),border=NA)
polygon(c(45,47,47,45),c(75,75,90,90),col=rgb(.5,0,.5,.5),border=NA)
text(62.5,82.5,"colData")
@ 

\incfig{figure/beginner_plotSE}{.5\textwidth}{Diagram of \Rclass{SummarizedExperiment}}{
  Here we show the component parts of a \Rclass{SummarizedExperiment} object,
  and also its subclasses, such as the \Rclass{DESeqDataSet} which is explained in the 
  next section. The \Robject{assay(s)} (red block) contains the matrix (or matrices) of 
  summarized values, the \Robject{rowData} (blue block) contains information about the 
  genomic ranges, and the \Robject{colData} (purple block) contains information 
  about the samples or experiments. The highlighted line in each block represents the 
  first row (note that the first row of \Robject{colData} lines up with the first
  column of the \Robject{assay}.
}


This example code above actually only counts a small subset of reads from the
original experiment: for 3 samples and for 100 genes. Nevertheless, we can still 
investigate the resulting \Rclass{SummarizedExperiment} by looking at the counts
in the \Robject{assay} slot, the phenotypic data about the samples in \Robject{colData} slot
(in this case an empty \Rclass{DataFrame}), and the data about the genes in the \Robject{rowData} slot.

<<examineSE>>=
se
head( assay(se) )
colSums( assay(se) )
colData(se)
rowData(se)
@ 

Note that the \Robject{rowData} slot is a \Rclass{GRangesList}, which contains
all the information about the exons for each gene, i.e., for each row of the count table.

This \Rclass{SummarizedExperiment} object \Robject{se} is then all we need to start our analysis.
In the following section we will show how to create the data object which is used in \deseqtwo{}, 
either using the \Rclass{SummarizedExperiment}, or in general, a count table which has 
been loaded into R.

\subsection{Experiment data}

\subsubsection{The DESeqDataSet, column metadata, and the design formula}

Each Bioconductor software package often has a special class of data object,
which contains special slots and requirements. The data object class in \deseqtwo{}
is the \Rclass{DESeqDataSet}, which is built on top of the \Rclass{SummarizedExperiment}.
One main differences is that the \Robject{assay} slot is instead accessed using the
\Rfunction{count} accessor, and the values in this matrix must non-negative integers.

A second difference is that the \Rclass{DESeqDataSet} has an associated ``design formula''.
The design is specified at the beginning of the analysis, as this will inform 
many of the \deseqtwo{} functions how to treat the samples in the analysis 
(one exception is the size factor estimation -- adjustment for differing
library sizes -- which does not depend on the design formula). 
The design formula tells which variables in the column metadata table (\Robject{colData})
specify the experimental design and how these factors should be used in the analysis.

The simplest design formula for differential expression would be
\Rfunction{\lowtilde{} condition}, where \Robject{condition} is a
column in \Robject{colData(dds)} which specifies which of two (or more
groups) the samples belong to.  For the parathyroid experiment, we
will specify \Rfunction{\lowtilde{} patient + treatment}, which means
that we want to test for the effect of treatment (the last factor),
controlling for the effect of patient (the first factor).

You can use R's formula notation to express any
experimental design that can be described within an ANOVA-like framework.
Note that \deseqtwo{} uses the same kind of formula as in base R, e.g., 
for use by the \Rfunction{lm} function. If the question of interest is whether a fold change
due to treatment is different across groups, for example across patients, ``interaction
terms'' can be included using models such as \Rfunction{\lowtilde{} patient + treatment + patient:treatment}.
More complex designs such as these are covered in the other \deseqtwo{} vignette.

In the following section, we will demonstrate the construction of the
\Rclass{DESeqDataSet} from two starting points:

\begin{enumerate}
\item from a \Rclass{SummarizedExperiment} object created by, e.g., \Rfunction{summarizeOverlaps} in the above example
\item more generally, from a count table (i.e. matrix) and a column metadata table which have been loaded into R
\end{enumerate}
  
For a full example of using the HTSeq Python package\footnote{described in \cite{Anders:2014:htseq}}
for read counting, please see the \Biocexptpkg{pasilla} or \Biocexptpkg{parathyroid} data package. 
For an example of generating the \Rclass{DESeqDataSet} from files produced by \texttt{htseq-count},
please see the other \deseqtwo{} vignette.

\subsubsection{Starting from SummarizedExperiment}

We load a prepared \Rclass{SummarizedExperiment}, which was generated using
\Rfunction{summarizeOverlaps} from publicly available data from the article by Felix Haglund et al.,
``Evidence of a Functional Estrogen Receptor in Parathyroid Adenomas'', J Clin Endocrin Metab, Sep
2012\footnote{\url{http://www.ncbi.nlm.nih.gov/pubmed/23024189}}.  Details on the generation of this
object can be found in the vignette for the \Biocexptpkg{parathyroidSE} package.

The purpose of the experiment was to investigate the role of the
estrogen receptor in parathyroid tumors. The investigators derived 
primary cultures of parathyroid adenoma cells from 4 patients. These 
primary cultures were treated with diarylpropionitrile (DPN), 
an estrogen receptor $\beta$ agonist, or with 4-hydroxytamoxifen (OHT).  
RNA was extracted at 24 hours and 48 hours from cultures under 
treatment and control.  The blocked design of the experiment allows
for statistical analysis of the treatment effects while controlling for patient-to-patient variation.

We first load the \deseqtwo{} package and the data package \Biocexptpkg{parathyroidSE},
which contains the example data set.

<<libraries>>=
library( "DESeq2" )
library( "parathyroidSE" )
@ 

The \Rfunction{data} command loads a preconstructed data object:

<<loadEcs>>=
data( "parathyroidGenesSE" )
se <- parathyroidGenesSE
colnames(se) <- se$run
@

Supposing we have constructed a \Rclass{SummarizedExperiment} using one of the 
methods described in the previous section, we now ensure that the 
object contains the necessary information about the samples, 
i.e., a table with metadata on the count table's columns stored in the \Robject{colData} slot:

<<coldataSE>>=
colData(se)[1:5,1:4]
@

This object does, because it was prepared so, as can be seen in the \Biocexptpkg{parathyroidSE} vignette.
However, users will most likely have to add pertinent sample/phenotypic 
information for the experiment at this stage.
We highly recommend keeping this information in a comma-separated value (CSV) or 
tab-separated value (TSV) file, which can be exported from an Excel spreadsheet.
The advantage of this over typing out the characters into an R script, is that 
while scrolling through a script, accidentally typed spaces or characters could lead 
to changes to the sample phenotypic information, leading to spurious results.

Suppose we have a CSV file which contains such data, we could read this file in 
using the base R \Rfunction{read.csv} function:

<<readcsv, eval=FALSE>>=
sampleInfo <- read.csv( "/path/to/file.CSV" )
@ 

<<sampleInfo, echo=FALSE>>=
sampleInfo <- data.frame(run=rev(se$run), 
                         pheno=rep(c("pheno1","pheno2"),length=ncol(se)))
@ 

Here we show a toy example of such a table. Note that the order
is not the same as in the \Rclass{SummarizedExperiment}. Here instead
of \Robject{run}, most users will have the filename of the BAM files
used for counting. We convert the \Robject{sampleInfo} object
into a \Rclass{DataFrame} which is the format of the \Robject{colData}.

<<showSampleInfo>>=
head( sampleInfo )
head( colnames(se) )
sampleInfo <- DataFrame( sampleInfo )
@ 

We create an index which will put them in the 
same order: the \Rclass{SummarizedExperiment} comes first because
this is the sample order we want to achieve. We then check to see
that we have lined them up correctly, and then we can add the
new data to the existing \Robject{colData}.

<<reorderSampleInfo>>=
seIdx <- match(colnames(se), sampleInfo$run)
head( cbind( colData(se)[ , 1:3 ], sampleInfo[ seIdx, ] ) )
colData(se) <- cbind( colData(se), sampleInfo[ seIdx, ] )
@ 

The following line builds the \Rclass{DESeqDataSet} from a \Rclass{SummarizedExperiment}
\Robject{se} and specifying a design formula, as described in the previous section.
The names of variables used in the design formula must be the names of columns in the
\Robject{colData} of \Robject{se}.

<<removeToy, echo=FALSE>>=
se$pheno <- NULL
@ 

<<fromSE>>=
ddsFull <- DESeqDataSet( se, design = ~ patient + treatment )
@

\subsubsection{Starting from count tables}

In the following section, we will show how to build an \Rclass{DESeqDataSet}
from a count table and a table of sample information. While the previous
section would be used to contruct a \Rclass{DESeqDataSet} from a
\Rclass{DESeqDataSet}, here we first extract the individual object
(count table and sample info) from a \Rclass{SummarizedExperiment}
in order to build it back up into a new object for demonstration purposes. 
In practice, the count table would either be read in from a file or perhaps generated by an 
R function like \Rfunction{featureCounts} from the \Biocpkg{Rsubread} package.

The information in a \Rclass{SummarizedExperiment} object can be accessed with 
accessor functions. For example, to see the actual data, i.e., here, the read counts, we
use the \Rfunction{assay} function. (The \Rfunction{head} function restricts the output to
the first few lines.)

<<countTable>>=
countdata <- assay( parathyroidGenesSE )
head( countdata )
@

In this count table, each row represents an Ensembl gene, 
each column a sequenced RNA library, 
and the values give the raw numbers of sequencing reads that were mapped to the
respective gene in each library.

We also have metadata on each of the samples (the ``columns'' of the count table):

<<colData>>=
coldata <- colData( parathyroidGenesSE )
rownames( coldata ) <- coldata$run
colnames( countdata ) <- coldata$run
@

<<colDataSubsetCols>>=
head( coldata[ , c( "patient", "treatment", "time" ) ] )
@

We now have all the ingredients to prepare our data object in a form that is suitable for analysis, namely:

\begin{itemize}
\item \Robject{countdata}: a table with the read counts
\item \Robject{coldata}: a table with metadata on the
  count table's columns
\end{itemize}

To now construct the data object from the matrix of counts and the metadata table, we use:

<<makeddsfull>>=
ddsFullCountTable <- DESeqDataSetFromMatrix(
  countData = countdata,
  colData = coldata,
  design = ~ patient + treatment)
ddsFullCountTable
@

We will continue with the object generated from the \Rclass{SummarizedExperiment} section.

\subsection{Collapsing technical replicates}

There are a number of samples which were sequenced in multiple
runs. For example, sample \Robject{SRS308873} was sequenced twice. To see,
we list the respective columns of the \Rfunction{colData}. (The use
of \Rfunction{as.data.frame} forces R to show us the full list, not just
the beginning and the end as before.)

<<columnData>>=
as.data.frame( colData( ddsFull )[ ,c("sample","patient","treatment","time") ] )
@ 

We recommend to first add together technical replicates (i.e., libraries
derived from the same samples), such that we have one column per sample. 
We have implemented a convenience function for this, which can take 
am object, either \Rclass{SummarizedExperiment} or \Rclass{DESeqDataSet},
and a grouping factor, in this case the sample name, 
and return the object with the counts summed up for each unique sample. 
This will also rename the columns of the object, such that they match the unique names which
were used in the grouping factor. Optionally, we can provide
a third argument, \Robject{run}, which can be used to paste together 
the names of the runs which were collapsed to create the new object.
Note that \Robject{dds\$variable} is equivalent to \Robject{colData(dds)\$variable}.

<<collapse>>=
ddsCollapsed <- collapseReplicates( ddsFull,
                                   groupby = ddsFull$sample, 
                                   run = ddsFull$run )
head( as.data.frame( colData(ddsCollapsed)[ ,c("sample","runsCollapsed") ] ), 12 )
@ 

We can confirm that the counts for the new object are equal to the 
summed up counts of the columns that had the same value for the 
grouping factor:

<<checkCollapsed>>=
original <- rowSums( counts(ddsFull)[ , ddsFull$sample == "SRS308873" ] )
all( original == counts(ddsCollapsed)[ ,"SRS308873" ] )
@ 

\section{Running the DESeq2 pipeline}\label{sec:runDESeq}

Here we will analyze a subset of the samples, namely those taken after 48 hours, 
with either control, DPN or OHT treatment, taking into account the multifactor design. 

\subsection{Preparing the data object for the analysis of interest}

First we subset the relevant columns from the full dataset:

<<subsetCols>>=
dds <- ddsCollapsed[ , ddsCollapsed$time == "48h" ]
@

Sometimes it is necessary to drop levels of the factors, in case that all the
samples for one or more levels of a factor in the design have been removed.
If time were included in the design formula, the following 
code could be used to take care of dropped levels in this column.

<<refactor>>=
dds$time <- droplevels( dds$time )
@

It will be convenient to make sure that \texttt{Control} is the \emph{first} level in the
treatment factor, so that the default log2 fold changes are calculated as treatment over
control and not the other way around. The function \Rfunction{relevel} achieves this:

<<relevel>>=
dds$treatment <- relevel( dds$treatment, "Control" )
@

A quick check whether we now have the right samples:

<<multifactorColData>>=
as.data.frame( colData(dds) )
@ 

\subsection{Running the pipeline}

Finally, we are ready to run the differential expression pipeline.
With the data object prepared, the \deseqtwo{} analysis can now be run with a single
call to the function \Rfunction{DESeq}:

<<subsetRows, echo=FALSE>>=
idx <- which(rowSums(counts(dds)) > 0)[1:4000]
dds <- dds[idx,]
@ 

<<runDESeq, cache=TRUE>>=
dds <- DESeq(dds)
@ 

This function will print out a message for the various steps it performs.
These are described in more detail in the manual page for \Rfunction{DESeq}, 
which can be accessed by typing \Robject{?DESeq}. Briefly these are:
the estimation of size factors (which control for differences in the library size
of the sequencing experiments), the estimation of dispersion for each gene,
and fitting a generalized linear model.

A \Rclass{DESeqDataSet} is returned which contains all the fitted information
within it, and the following section describes how to extract out 
results tables of interest from this object.

\subsection{Inspecting the results table}

Calling \Rfunction{results} without any arguments will extract
the estimated log2 fold changes and $p$ values for the last variable
in the design formula. If there are more than 2 levels for this variable
-- as is the case in this analysis -- \Rfunction{results} will extract the 
results table for a comparison of the last level over the first level.
The following section describes how to extract other comparisons.

<<extractResults>>=
res <- results( dds )
res
@

As \Robject{res} is a \Robject{DataFrame} object, it carries metadata with
information on the meaning of the columns:

<<resCols>>=
mcols(res, use.names=TRUE)
@

The first column, \Robject{baseMean}, is a just the average of the normalized count values,
dividing by size factors, taken over all samples. The remaining four columns refer to a specific
\emph{contrast}, namely the comparison of the levels \emph{DPN}
versus \emph{Control} of the factor variable \emph{treatment}. See the help page 
for \Rfunction{results} (by typing \Rfunction{?results}) for information
on how to obtain other contrasts.

The column \Robject{log2FoldChange} is the effect size estimate. It tells us 
how much the gene's expression seems to have changed due to treatment with DPN
in comparison to control. This value is reported on a logarithmic scale to base 2: for example, a log2 fold change
of 1.5 means that the gene's expression is increased by a multiplicative factor of $2^{1.5}\approx 2.82$.

Of course, this estimate has an uncertainty associated with it, which is available in the
column \Robject{lfcSE}, the standard error estimate for the log2 fold change estimate.  We
can also express the uncertainty of a particular effect size estimate as the result of a
statistical test. The purpose of a test for differential expression is to test whether the
data provides sufficient evidence to conclude that this value is really different from
zero. \deseqtwo{} performs for each gene a \emph{hypothesis test} 
to see whether evidence is sufficient to decide against the \emph{null hypothesis}
that there is no effect of the treatment on the gene and that the observed difference
between treatment and control was merely caused by experimental variability (i.\,e., the
type of variability that you can just as well expect between different samples in the same
treatment group). As usual in statistics, the result of this test is reported as a 
\emph{$p$ value}, and it is found in the column \Robject{pvalue}. (Remember that a $p$ value indicates
the probability that a fold change as strong as the observed one, or even stronger, would
be seen under the situation described by the null hypothesis.)

We note that a subset of the $p$ values in \Robject{res} are \Robject{NA} (``not
available''). This is \Rfunction{DESeq}'s way of reporting that all counts for this gene
were zero, and hence not test was applied. In addition, $p$ values can be 
assigned \Robject{NA} if the gene was excluded from analysis because it 
contained an extreme count outlier. For more information, see the outlier
detection section of the advanced vignette.

\subsection{Other comparisons}

In general, the results for a comparison of any two levels of
a variable can be extracted using the \Robject{contrast} 
argument to \Rfunction{results}. The user should specify three values: 
the name of the variable, the name of the
level in the numerator, and the name of the level in the denominator.
Here we extract results for the log2 of the fold change of DPN $/$ Control.

<<resultsOther>>=
res <- results( dds, contrast = c("treatment", "DPN", "Control") )
res
@ 

If results for an interaction term are desired, the \Robject{name}
argument of \Rfunction{results} should be used. Please see the more advanced
vignette for more details.

\subsection{Multiple testing}
Novices in high-throughput biology often assume that thresholding these $p$ values at a low value,
say 0.01, as is often done in other settings, would be appropriate -- but it is not. We briefly
explain why:

There are \Sexpr{sum( res$pvalue < 0.01, na.rm=TRUE )} genes with a $p$ value below
0.01 among the \Sexpr{sum( !is.na(res$pvalue) )} genes, for which the test succeeded
in reporting a $p$ value:

<<rawpvalue>>=
sum( res$pvalue < 0.01, na.rm=TRUE )
table( is.na(res$pvalue) )
@

Now, assume for a moment that the null hypothesis is true for all genes, i.e., no
gene is affected by the treatment with DPN. Then, by the definition of \emph{$p$ value},
we expect up to 1\% of the genes to have a $p$ value below 0.01. This amounts to
\Sexpr{round( sum( !is.na(res$pvalue) ) * 0.01 )} genes.
If we just considered the list of genes with a $p$ value below 0.01 as differentially
expressed, this list should therefore be expected to contain up to 
$\Sexpr{round( sum( !is.na(res$pvalue) ) * 0.01)} / \Sexpr{sum( res$pvalue < 0.01, na.rm=TRUE ) } = 
 \Sexpr{round( sum( !is.na(res$pvalue) ) * 0.01 / sum( res$pvalue < 0.01, na.rm=TRUE ) * 100, 0 )}$\% 
false positives!

\deseqtwo{} uses the so-called Benjamini-Hochberg (BH) adjustment; in brief, this method calculates
for each gene an \emph{adjusted $p$ value} which answers the following question: if one
called significant all genes with a $p$ value less than or equal to this gene's $p$ value threshold,
what would be the fraction of false positives (the \emph{false discovery rate}, FDR) among
them (in the sense of the calculation outlined above)? These values, called the BH-adjusted
$p$ values, are given in the column \Robject{padj} of the \Robject{results} object.

Hence, if we consider a fraction of 10\% false positives acceptable, we can consider all
genes with an \emph{adjusted} $p$ value below 10\%=0.1 as significant. How many such genes
are there?

<<adjpvalue>>=
sum( res$padj < 0.1, na.rm=TRUE )
@

We subset the results table to these genes and then sort it by the log2 fold change
estimate to get the significant genes with the strongest down-regulation

<<strongGenes>>=
resSig <- res[ which(res$padj < 0.1 ), ]
head( resSig[ order( resSig$log2FoldChange ), ] )
@

and with the strongest upregulation

<<strongGenesUp>>=
tail( resSig[ order( resSig$log2FoldChange ), ] )
@

\subsection{Diagnostic plots}

A so-called MA plot provides a useful overview for an experiment
with a two-group comparison:

<<beginner_MA>>=
plotMA( res, ylim = c(-1, 1) )
@ 

The plot (Fig.\ \ref{figure/beginner_MA}) represents each gene with a dot. The $x$ axis
is the average expression over all samples, the $y$ axis the log2
fold change between treatment and control. Genes with an adjusted $p$ value
below a threshold (here 0.1, the default) are shown in red. 
 
\incfig{figure/beginner_MA}{.5\textwidth}{MA-plot}{
  The MA-plot shows the log2 fold changes from the treatment over
  the mean of normalized counts, i.e. the average of counts normalized by
  size factor. The \deseqtwo{} package incorporates a prior on log2
  fold changes, resulting in moderated estimates 
  from genes with low counts and highly variable counts,
  as can be seen by the narrowing of spread of points on the left side of the plot.
}

This plot demonstrates that only genes with a large average normalized count contain
sufficient information to yield a significant call.

Also note \deseqtwo's shrinkage estimation of log fold changes (LFCs): When count values
are too low to allow an accurate estimate of the LFC, the value is ``shrunken'' towards
zero to avoid that these values, which otherwise would frequently be 
unrealistically large, dominate the top-ranked log fold changes.

Whether a gene is called significant depends not only on its LFC but also on its
within-group variability, which \deseqtwo{} quantifies as the \emph{dispersion}. For 
strongly expressed genes, the dispersion can be understood as a squared coefficient of
variation: a dispersion value of 0.01 means that the gene's expression tends to differ by
typically $\sqrt{0.01}=10\%$ between samples of the same treatment group. For weak genes,
the Poisson noise is an additional source of noise, which is added to the dispersion.

The function \Rfunction{plotDispEsts} visualizes \deseqtwo's dispersion estimates:

<<beginner_dispPlot>>=
plotDispEsts( dds, ylim = c(1e-6, 1e1) )
@

\incfig{figure/beginner_dispPlot}{.5\textwidth}{Plot of dispersion estimates}{See text for details}

The black points are the dispersion estimates for each gene as obtained by considering
the information from each gene separately. Unless one has many samples, these
values fluctuate strongly around their true values. Therefore, we fit the red
trend line, which shows the dispersions' dependence on the mean, and then shrink each
gene's estimate towards the red line to obtain the final estimates (blue points)
that are then used in the hypothesis test. The blue circles above the main ``cloud'' of points
are genes which have high gene-wise dispersion estimates which are labelled as 
dispersion outliers. These estimates are therefore not shrunk toward the fitted trend line.

\incfig{figure/beginner_pvalHist}{.5\textwidth}{Histogram}{of the $p$ values returned by the
  test for differential expression}

Another useful diagnostic plot is the histogram of the $p$ values (Fig.~\ref{figure/beginner_pvalHist}).

<<beginner_pvalHist, dev="pdf">>=
hist( res$pvalue, breaks=20, col="grey" )
@

\section{Independent filtering}

The MA plot (Figure~\ref{figure/beginner_MA}) highlights an important property of RNA-Seq data.
For weakly expressed genes, we have no chance of seeing differential
expression, because the low read counts suffer from so high Poisson
noise that any biological effect is drowned in the uncertainties from the
read counting. 
We can also show this by examining the ratio of small $p$ values
(say, less than, 0.01) for genes binned by mean normalized count:

<<beginner_ratioSmallP, dev="pdf", fig.width=8, fig.height=4>>=
# create bins using the quantile function
qs <- c( 0, quantile( res$baseMean[res$baseMean > 0], 0:7/7 ) )
# "cut" the genes into the bins
bins <- cut( res$baseMean, qs )
# rename the levels of the bins using the middle point
levels(bins) <- paste0("~",round(.5*qs[-1] + .5*qs[-length(qs)]))
# calculate the ratio of $p$ values less than .01 for each bin
ratios <- tapply( res$pvalue, bins, function(p) mean( p < .01, na.rm=TRUE ) )
# plot these ratios
barplot(ratios, xlab="mean normalized count", ylab="ratio of small $p$ values")
@

\incfig{figure/beginner_ratioSmallP}{.9\textwidth}{Ratio of small p values}{for groups of genes 
binned by mean normalized count}

At first sight, there may seem to be little benefit in filtering out these genes. After
all, the test found them to be non-significant anyway. However, these genes have an
influence on the multiple testing adjustment, whose performance improves if such genes are
removed. By removing the weakly-expressed genes from the input to the FDR procedure, we
can find more genes to be significant among those which we keep, and so
improved the power of our test. This approach is known as \emph{independent filtering}. 

The \deseqtwo{} software automatically performs independent filtering which
maximizes the number of genes which will have adjusted $p$ value less 
than a critical value (by default, \Robject{alpha} is set to 0.1). 
This automatic independent filtering
is performed by, and can be controlled by, the \Rfunction{results} function.
We can observe how the number of rejections changes for various
cutoffs based on mean normalized count. The following optimal threshold
and table of possible values is stored as an \emph{attribute} of the 
results object.

<<beginner_filtByMean, dev="pdf">>=
attr(res,"filterThreshold")
plot(attr(res,"filterNumRej"),type="b",
     xlab="quantiles of 'baseMean'",
     ylab="number of rejections")
@

\incfig{figure/beginner_filtByMean}{.5\textwidth}{Independent filtering.}{\deseqtwo{}
automatically determines a threshold, filtering on mean normalized count,
which maximizes the number of genes which will have an adjusted
$p$ value less than a critical value.}

The term \emph{independent} highlights an important caveat. Such filtering is permissible
only if the filter criterion is independent of the actual test
statistic~\cite{Bourgon:2010:PNAS}. Otherwise, the filtering would invalidate the test and
consequently the assumptions of the BH procedure.  This is why we filtered on the average
over \emph{all} samples: this filter is blind to the assignment of samples to the
treatment and control group and hence independent.
 
\subsection{Adding gene names}

Our result table only uses Ensembl gene IDs, but gene names may be more
informative. Bioconductor's \Biocpkg{biomaRt} package can help with mapping various
ID schemes to each other. 

First, we split up the rownames of the results object, which
contain ENSEMBL gene ids, separated by the plus sign, \Robject{+}.
The following code then takes the first id for each gene by invoking 
the open square bracket function \Robject{"["} and the argument, \Robject{1}.

<<>>=
res$ensembl <- sapply( strsplit( rownames(res), split="\\+" ), "[", 1 )
@ 

The following chunk of code uses the ENSEMBL mart, querying 
with the ENSEMBL gene id and requesting the Entrez gene id 
and HGNC gene symbol.

<<geneAnnot, cache=TRUE>>=
library( "biomaRt" )
ensembl = useMart( "ensembl", dataset = "hsapiens_gene_ensembl" )
genemap <- getBM( attributes = c("ensembl_gene_id", "entrezgene", "hgnc_symbol"), 
                 filters = "ensembl_gene_id", 
                 values = res$ensembl, 
                 mart = ensembl )
idx <- match( res$ensembl, genemap$ensembl_gene_id )
res$entrez <- genemap$entrezgene[ idx ]
res$hgnc_symbol <- genemap$hgnc_symbol[ idx ]
@ 

Now the results have the desired external gene ids:

<<showAnnot>>=
head(res,4)
@ 

\subsection{Exporting results}

Finally, we note that you can easily save the results table in a CSV file,
which you can then load with a spreadsheet program such as Excel:

<<geneAnnotRes>>=
res[1:2,]
@ 

<<writeCSV, eval=FALSE>>=
write.csv( as.data.frame(res), file="results.csv" )
@

\section{Working with rlog-transformed data}

\subsection{The rlog transform}

Many common statistical methods for exploratory analysis of multidimensional
data, especially methods for clustering and ordination (e.\,g., principal-component
analysis and the like), work best for (at least approximately)
homoskedastic data; this means that the variance of an observable quantity (i.e., here,
the expression strength of a gene) does not depend on the mean. In RNA-Seq data, 
however, variance grows with the mean. 
For example, if one performs PCA directly on a matrix of normalized read counts, the result
typically depends only on the few most strongly expressed genes because they show the
largest absolute differences between samples. A simple and often used strategy to
avoid this is to take the logarithm of the normalized count values plus a small pseudocount; 
however, now the genes with low counts tend to dominate the results because, due to the strong Poisson
noise inherent to small count values, they show the strongest relative differences 
between samples.

As a solution, \deseqtwo{} offers the \emph{regularized-logarithm transformation},
or \emph{rlog} for short. For genes with high counts, the rlog transformation
differs not much from an ordinary log2 transformation. For genes with lower counts, however,
the values are shrunken towards the genes' averages across all samples. Using
an empirical Bayesian prior in the form of a \emph{ridge penality}, this is done such
that the rlog-transformed data are approximately homoskedastic.

Note that the rlog transformation is provided for applications other 
than differential testing. For differential testing we recommend the 
\Rfunction{DESeq} function applied to raw counts, as described earlier
in this vignette, which also takes into account the dependence of the 
variance of counts on the mean value during the dispersion estimation step.

The function \Rfunction{rlogTransform} returns a \Rclass{SummarizedExperiment} object
which contains the rlog-transformed values in its \Rclass{assay} slot:

<<rld, cache=TRUE>>=
rld <- rlog( dds )
head( assay(rld) )
@ 

To show the effect of the transformation, we plot the first sample against the 
second, first simply using the \Rfunction{log2} function (after adding 1,
to avoid taking the log of zero), and then using the rlog-transformed values.

\incfig{figure/beginner_rldPlot}{.9\textwidth}{Scatter plot of sample 2 vs sample 1.}{
  Left: using an ordinary $log_2$ transformation. Right: Using the rlog transformation.}

<<beginner_rldPlot,fig.width=10,fig.height=5>>=
par( mfrow = c( 1, 2 ) )
plot( log2( 1+counts(dds, normalized=TRUE)[, 1:2] ), col="#00000020", pch=20, cex=0.3 )
plot( assay(rld)[, 1:2], col="#00000020", pch=20, cex=0.3 )
@

Note that, in order to make it easier to see where several points are plotted on top of each other,
we set the plotting color to a semi-transparent black (encoded as \Rfunction{\#00000020})
and changed the points to solid disks (\Rfunction{pch=20}) with reduced size
(\Rfunction{cex=0.3})\footnote{The function \Rfunction{heatscatter} from the package
  \CRANpkg{LSD} offers a colorful alternative.}.

In Figure~\ref{figure/beginner_rldPlot}, we can see how genes with low counts seem to be excessively variable
on the ordinary logarithmic scale, while the rlog transform compresses differences for genes
for which the data cannot provide good information anyway.

\subsection{Sample distances}

A useful first step in an RNA-Seq analysis is often to assess overall 
similarity between samples: Which samples are similar to each other, 
which are different? Does this fit to the expectation from the 
experiment's design?

\incfig{figure/beginner_sampleDistHeatmap}{.5\textwidth}{Heatmap of Euclidean sample distances after rlog transformation.}

We use the R function \Rfunction{dist} to calculate the Euclidean distance
between samples. To avoid that the distance measure is dominated by a few highly variable genes,
and have a roughly equal contribution from all genes, we use it on the rlog-transformed data:

<<euclDist>>=
sampleDists <- dist( t( assay(rld) ) )
sampleDists
@

Note the use of the function \Rfunction{t} to transpose the data matrix. We need
this because \Rfunction{dist} calculates distances between data \emph{rows} and
our samples constitute the columns.

We visualize the distances in a heatmap, using the function \Rfunction{heatmap.2} from
the \CRANpkg{gplots} package.

<<beginner_sampleDistHeatmap, dev="pdf">>=
sampleDistMatrix <- as.matrix( sampleDists )
rownames(sampleDistMatrix) <- paste( rld$treatment, 
   rld$patient, sep="-" )
colnames(sampleDistMatrix) <- NULL   
library( "gplots" )
library( "RColorBrewer" )
colours = colorRampPalette( rev(brewer.pal(9, "Blues")) )(255)
heatmap.2( sampleDistMatrix, trace="none", col=colours)
@ 

Note that we have changed the row names of the distance matrix to contain
treatment type and patient number instead of sample ID, so that we have
all this information in view when looking at the heatmap 
(Fig.~\ref{figure/beginner_sampleDistHeatmap}).

\incfig{figure/beginner_samplePCA}{.5\textwidth}{Principal components analysis (PCA)}{ of samples after rlog transformation.}

Another way to visualize sample-to-sample distances is a principal-components
analysis (PCA). In this ordination method, the data points (i.e., here, the samples)
are projected onto the 2D plane such that they spread out optimally (Fig.\ \ref{figure/beginner_samplePCA}).
If we only had two treatments, the \Rfunction{plotPCA} will automatically use a paired color palette
for each combination of the levels of patient and treatment. As we have three treatments, 
we supply a vector which specifies three shades of red, green, blue and purple for each patient.

<<beginner_samplePCA, dev="pdf">>=
ramp <- 1:3/3
cols <- c(rgb(ramp, 0, 0), 
          rgb(0, ramp, 0), 
          rgb(0, 0, ramp), 
          rgb(ramp, 0, ramp))
print( plotPCA( rld, intgroup = c( "patient", "treatment"), col=cols ) )
@

Here, we have used the function \Rfunction{plotPCA} which comes with \deseqtwo.
The two terms specified as \Rfunction{intgroup} are column names from our
sample data; they tell the function to use them to choose colours. 

From both visualizations, we see that the differences between patients is much larger 
than the difference between treatment and control samples of the same patient. This
shows why it was important to account for this paired design (``paired'', because each
treated sample is paired with one control sample from the \emph{same} patient). We did
so by using the design formula \texttt{\lowtilde{} patient + treatment} when setting up the
data object in the beginning. Had we used an un-paired analysis, by specifying
only \texttt{\lowtilde{} treatment}, we would not have found many hits, because then,
the patient-to-patient differences would have drowned out any treatment effects.

Here, we have performed this sample distance analysis towards the end of our analysis.
In practice, however, this is a step suitable to give a first overview on the data.
Hence, one will typically carry out this analysis as one of the first steps in an analysis.
To this end, you may also find the function \Rfunction{arrayQualityMetrics}, from the
package of the same name, useful. 

\subsection{Gene clustering}

\incfig{figure/beginner_geneHeatmap}{.5\textwidth}{Heatmap with gene clustering.}

In the heatmap of Fig.~\ref{figure/beginner_sampleDistHeatmap}, the dendrogram at the side shows
us a hierarchical clustering of the samples. Such a clustering can also be performed 
for the genes. 

Since the clustering is only relevant for genes that actually carry signal, one usually carries it out only for
a subset of most highly variable genes. Here, for demonstration, let us select the 35 genes
with the highest variance across samples:

<<topVarGenes>>=
library( "genefilter" )
topVarGenes <- head( order( rowVars( assay(rld) ), decreasing=TRUE ), 35 )
@

The heatmap becomes more interesting if we do not look at absolute expression strength
but rather at the amount by which each gene deviates in a specific sample from
the gene's average across all samples. Hence, we center and scale each genes' values across
samples, and plot a heatmap.

<<beginner_geneHeatmap, fig.width=9, fig.height=9>>=
heatmap.2( assay(rld)[ topVarGenes, ], scale="row", 
     trace="none", dendrogram="column", 
     col = colorRampPalette( rev(brewer.pal(9, "RdBu")) )(255))
@

We can now see (Fig. \ref{figure/beginner_geneHeatmap}) blocks of genes which covary across patients.
Often, such a heatmap is insightful, even though here, seeing these variations
across patients is of limited value because we are rather interested in the effects
between the treatments from each patient. 

\bibliography{library}

\section{Session Info}

As last part of this document, we call the function \Rfunction{sessionInfo}, which
reports the version numbers of R and all the packages used in this session. It is
good practice to always keep such a record as it will help to trace down what has
happened in case that an R script ceases to work because a package has been
changed in a newer version. The session information should also always 
be included in any emails to the Bioconductor mailing list.

<<sessInfo, results="asis", echo=FALSE>>=
toLatex(sessionInfo())
@

<<resetOptions, results="hide", echo=FALSE>>=
options(prompt="> ", continue="+ ")
@


\end{document}
